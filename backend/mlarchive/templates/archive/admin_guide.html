{% extends "base.html" %}

{% block title %}Mail Archive - Admin Guide{% endblock %}

{% block header %}{{ block.super }} - Admin Guide{% endblock %}

{% block content %}

<div class="admin-guide container-fluid">
    <ul class="mt-4">
        <li><a href="#add_list">How do I add a new list?</a></li>
        <li><a href="#import">How do I import messages from an archive file?</a></li>
        <li><a href="#import_single">How do I import a single message file?</a></li>
        <li><a href="#delete_message">How do I delete unwanted messages from the archive?</a></li>
        <li><a href="#rebuild_index">How do I rebuild the index for a subset of messages?</a></li>
        <li><a href="#subpoena">How do I collect messages for response to a subpoena?</a></li>
        <li><a href="#rebuild_index_in_place">How do I rebuild the index in place?</a></li>
        <li><a href="#admin">Using the Admin Page and Handling Spam</a></li>
        <li><a href="#memcached">Memcached</a></li>
        <li><a href="#rabbitmq">RabbitMQ</a></li>
        <li><a href="#celery">Celery</a></li>
    </ul>
    <hr>

    <span id="add_list"></span>
    <h2>How do I add a new list?</h2>
    <p>Lists that do not already exist are added automatically when new mail is received
    from mailman.  NOTE: if the list is private, an authorized user will need to use the
    Django Administrative interface:<br>
    <a href="https://{{ request.META.HTTP_HOST }}/admin">Django Admin</a></p>

    <span id="import"></span>
    <h2>How do I import messages from an archive file?</h2>
    <p>The mail archive supports imports from mbox files (or directories of files).  Use the following procedure to load messages into the live archive.<br>
    <pre>cd /a/mailarch/current
source env/bin/activate
cd backend
./manage.py load [path-to-file/dir] -l [listname]</pre>
    It may take some minutes to run, depending on how many messages are being imported.  It will print some statistics on completion.
    </p>

    <span id="import_single"></span>
    <h2>How do I import a single message file?</h2>
    <p>On rare occassion a message may fail to import, a glitch during the middle of an upgrade for example. Use the following command to load a single message file.<br>
    <pre>cd /a/mailarch/current/backend/mlarchive/bin
./archive-mail.py [listname] --public < /a/mailarch/data/incoming/ietf.public.nu0BnIRs</pre>
Use search to check that the message loaded properly.
    </p>

    <span id="delete_message"></span>
    <h2>How do I delete unwanted messages from the archive?</h2>
    <p>Sign in (must have superuser privileges).  Select Remove Messages from the Admin menu.
    Use the form to search for messages.  Select the messages you want to delete.
    Choose "Remove selected messages" action and click Go.  Messages will be moved to the
    [INSTALL]/data/archive/[listname]/_removed directory and removed from the index.<br>
    <a href="{% url "archive_admin" %}">Archive Admin</a></p>

    <span id="rebuild_index"></span>
    <h2>How do I rebuild the index for a subset of messages?</h2>
    <p>If you need to rebuild the index for messages updated within a specific date range,
    first stop the Celery worker from processing new index updates (the updates will safely
    queue in RabbitMQ and be processed when Celery is restarted.
    <pre>sudo systemctl stop celeryd.service</pre>
    Then use the update_index command
    <pre>cd /a/mailarch/current
source env/bin/activate
cd backend
./manage.py update_index --start='2014-01-14T00:00:00' --end='2014-01-16T23:59:59'
-- or --
./manage.py update_index --age=1</pre>
    Then restart Celery
    <pre>sudo systemctl start celeryd.service</pre>
    </p>

    <span id="subpoena"></span>
    <h2>How do I collect messages for response to a subpoena?</h2>
    <p>If the subpoena calls for messages from a specific list containing a search term, use the
    standard search interface to export messages from the archive. For example, if the request is
    for messages from acme employees about an RFC the request could look like this (export the
    messages for further processing):</p>
    <pre>from:acme.com AND (RFC1000 OR "RFC 1000" OR "draft-ietf-name-of-id")</pre>
    <p>In addition you can collect
    messages that aren't in the index (spam, dupes, etc.) in this way:</p>
    <pre>mkdir /tmp/sub012214
cd /a/mailarch/data/archive/[listname]/
for fil in `find . -path "./_*/*" ! -path "./_attachments/*" -exec grep -l searchterm {} \;`; do cp $fil /tmp/sub012214/; done;
cd /tmp
tar cvf sub012214.tar ./sub012214</pre>

    <span id="rebuild_index_in_place"></span>
    <h2>How do I rebuild the index in place?</h2>
    <p><strong>Overview</strong>: Occasionally there are code changes that effect how messages are indexed. Assuming the changes are backwards compatible you can deploy the new code then rebuild the entire index. In brief the process is: run rebuild_index command using a new index name, then point the archive index alias to this new index.</p>
    <p>Review the current index and alias settings using the commands:</p>
    <pre>curl -X GET "localhost:9200/_cat/indices/?v"
    curl -X GET "localhost:9200/mail-archive/_alias/*?pretty"</pre>
    <p>Create a settings file called backend/mlarchive/settings/settings_rebuild.py with the following contents</p>
    <pre># settings/settings_rebuild.py
from .base import *

# ELASTICSEARCH SETTINGS
ELASTICSEARCH_INDEX_NAME = 'mail-archive-NN'
ELASTICSEARCH_SILENTLY_FAIL = True
ELASTICSEARCH_CONNECTION = {
    'URL': 'http://127.0.0.1:9200/',
    'INDEX_NAME': 'mail-archive-NN',
}</pre>
    <p>Where NN is the next increment. Then run the following command from cron</p>
    <pre>cd /a/mailarch/current && source env/bin/activate && cd backend && export PYTHONPATH=$PWD && ./manage.py rebuild_index --batch-size=20000 --noinput --settings=mlarchive.settings.settings_rebuild</pre>
    <p>This will take ~10 hours. When complete check that the new index is roughly the same size as the live index. The live index will be slightly larger as new messages have been added</p>
    <pre>curl -X GET "localhost:9200/_cat/indices/?v"</pre>
    <p>Assuming all looks good change the alias. ** Replace ${newIndex} with index name **</p>
    <pre>curl -XPOST localhost:9200/_aliases -H 'Content-Type: application/json' -d '{"actions":[{"remove" : {"index" : "*", "alias" : "mail-archive"}},{"add" : { "index" : "${newIndex}", "alias" : "mail-archive" }}]}'</pre>
    <p>Confirm that the new index is now being used by running the above _cat/indices command and checking that docs.count increases as new messages are added. During the new index build some number of messages will have come in, that won't be in the new index. To index these use the "How do I rebuild the index for a subset of messages?" instructions above to index messages from the last N hours using --age. Go back a little further than the start of the rebuild, messages already indexed will be skipped. Later, when you are SURE everything is working properly delete the old index.</p>
    <pre>curl -X DELETE "localhost:9200/${oldIndex}?pretty"</pre>

    <span id="admin"></span>
    <h2>Using the Admin Page and Handling Spam</h2>
    <p>The <a href="{% url "archive_admin" %}">Admin Page</a> lets you search for messages and then perform an action on those messages.  There are currently two supported actions:<br>
<strong>Remove:</strong> moves the message to the archive/[list]/_removed directory, and removes it from the searchable index<br>
<strong>Mark not spam:</strong> clears the spam_score message attribute</p>
<p>The admin page also has a special <strong>Spam Mode</strong>.  When enabled, the messages can be quickly sorted using the arrow keys, right for spam, left for not spam.  When a message is sorted as not spam, all other messages from the same sender are automatically sorted as not spam as well.  And when a message is sorted as spam all messages with an identical subject are sorted as spam.  Sometimes this may not be desired, so the behaviour can be disabled.  Spam mode is useful, for example, when a list has lots of spam in a given date range.  The user can sort through thousands of messages in a very efficient manner.</p>
<p>The mail archive supports custom inspectors for detecting Spam.  Inspectors are implemented as classes in mlarchive.archive.inspectors.  Use the settings.INSPECTORS variable to apply inspectors to incoming messages of specific lists.  For example:
<pre>INSPECTORS = {
    'SpamLevelSpamInspector': {'includes': ['rfc-dist', 'ipp']}
}</pre>
SpamLevelSpamInspector checks the X-Spam-Level header for a score of 5 or greater.  There is also a utility script mlarchive/bin/check_spam.py which can be used to run an inspector on an existing archive and remove messages or mark them for manual inspection.
</p>

    <h1>Auxiliary Services</h1>
    <span id="memcached"></span>
    <h2>Memcached</h2>
    <p>Memcached is the cache backend for the Email Archive.<br><br>
    Start / Stop memcached
    <pre>service memcached start|stop|restart</pre>
    Status from the command line
    <pre>$ telnet localhost 11211
Trying 127.0.0.1...
Connected to localhost.
Escape character is '^]'.
stats
stats items
quit</pre>
    To flush the queue<br>
    <pre>flush_all</pre>
    From the command line<br>
    <pre>echo 'flush_all' | nc localhost 11211</pre>
    
    References:<br>
    <a href="http://memcached.org">Memcache Homepage</a><br>
    <a href="http://www.pal-blog.de/entwicklung/perl/memcached-statistics-stats-command.html">Memcached Statistics</a>

    <span id="rabbitmq"></span>
    <h2>RabbitMQ</h2>
    Rabbitmq is the messaging backend for the Email Archive.  It is used to queue index update requests.  Celery is the corresponding piece that consumes the queued tasks.<br><br>

    Start / Stop Rabbitmq server
    <pre>service rabbitmq-server start|stop|restart
** NOTE ** stop celery first, or restart after a rabbitmq restart</pre>

    Check status of server
    <pre>rabbitmqctl status</pre>

    List info for the message queue
    <pre>rabbitmqctl list_queues
rabbitmqctl list_queues name messages messages_ready messages_unacknowledged</pre>

    Reset message queue (removes all messages!)
    <pre>rabbitmqctl stop_app
rabbitmqctl reset
rabbitmqctl start_app</pre>
    List plugins
    <pre>rabbitmq-plugins list</pre>
    
    <br>
    Admin:<br>
    <a href="http://{{ request.META.HTTP_HOST }}:55672/">RabbitMQ Management (Web GUI)</a><br>
    
    <br>
    References:<br>
    <a href="https://www.rabbitmq.com/man/rabbitmqctl.1.man.html">rabbitmqctl man page</a>

    <span id="celery"></span>
    <h2>Celery</h2>
    Celery is the asynchronous task queue used to queue index updates.  It uses RabbitMQ as it's backend<br>
    <br>
    Restart
    <pre># systemctl restart celeryd.service</pre>

    <br>
    Admin:<br>
    Config File: /etc/default/celeryd<br>
    Log File: /var/log/celery/worker1.log<br>
    <pre>$ celery status
$ celery report</pre>
    Before you can access the Celery web admin tool, Flower, you need to start a 
    web-server:
    <pre>cd /a/mailarch/current
source env/bin/activate
export PYTHONPATH=/a/mailarch/current/backend
export DJANGO_SETTINGS_MODULE=mlarchive.settings.settings
celery -A mlarchive flower</pre>
    <a href="http://{{ request.META.HTTP_HOST }}:5555/">Celery Management</a><br>

    Troubleshooting: ensure perms correct on /var/log/mail-archive/mlarchive.log<br>
    Troubleshooting: inspect log, run worker manually to check for errors
    <pre>> Starting nodes...
> worker1@ietfa.amsl.com: * Child terminated with errorcode 255
FAILED

# journalctl --unit=celeryd

# su - nobody
$ cd /a/mailarch/current/backend
$ export PYTHONPATH=$PWD
$ export DJANGO_SETTINGS_MODULE=mlarchive.settings.production
$ /a/mailarch/current/env/bin/celery worker -A mlarchive.celeryapp:app</pre>
    <br>
    Solutions for Log File Errors:<br>
    DatabaseOpeningError: check perms on database files<br>
    DatabaseError:<br>
    <br>
    
    References:<br>
    <a href="http://docs.celeryproject.org/en/latest/userguide/monitoring.html">Celery admin & monitoring</a><br>
    <a href="http://celery.readthedocs.org/en/latest/index.html">Documentation</a><br>
    
</div> <!-- admin_page -->
{% endblock %}


{% block footer %}
  {% with extra_class="scrolling" %}
    {% include "includes/footer.html" %}
  {% endwith %}
{% endblock %}
